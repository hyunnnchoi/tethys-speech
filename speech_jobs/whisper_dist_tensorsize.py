import tensorflow as tf
import numpy as np
import json
import os
import time
import argparse
from tensorflow.keras import layers, Model
from scipy import stats  # skewness ê³„ì‚°ì„ ìœ„í•´ ì¶”ê°€


# í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì •ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ë“¤
TENSOR_SIZE_TRACKER = {
    'current_step_tensors': [],
    'total_tensor_size': 0,
    'step_tensor_sizes': [],
    'operation_tensor_sizes': {}
}


class TensorProfiler:
    """Tiresias ë…¼ë¬¸ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ í…ì„œ ì‚¬ì´ì¦ˆë¥¼ ì¸¡ì •í•˜ëŠ” ê³ ê¸‰ í”„ë¡œíŒŒì¼ëŸ¬"""
    
    def __init__(self, log_dir='/workspace/tensor_logs'):
        self.log_dir = log_dir
        self.current_step = 0
        self.current_step_size = 0
        self.step_tensor_sizes = []
        self.operation_tensor_sizes = {}
        self.tensor_details = []
        self.gradient_sizes = []
        self.parameter_sizes = []
        self.memory_usage = []
        
        # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
        os.makedirs(log_dir, exist_ok=True)
        
        # í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê·¸ íŒŒì¼
        self.tensor_log_file = open(os.path.join(log_dir, 'tensor_sizes.txt'), 'w')
        self.tensor_log_file.write("step,operation,tensor_type,size_bytes,size_mb,shape\n")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼  
        self.memory_log_file = open(os.path.join(log_dir, 'memory_usage.txt'), 'w')
        self.memory_log_file.write("step,gpu_memory_mb,cpu_memory_mb\n")
        
        # ìš”ì•½ ë¡œê·¸ íŒŒì¼
        self.summary_log_file = open(os.path.join(log_dir, 'summary.txt'), 'w')
        self.summary_log_file.write("step,total_tensor_size_mb,num_operations,avg_tensor_size_mb\n")
        
        # Tiresias ìŠ¤íƒ€ì¼ í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê·¸ íŒŒì¼
        self.tiresias_log_file = open(os.path.join(log_dir, 'tiresias_tensorsize.txt'), 'w')
        self.tiresias_log_file.write("step,tensorsize_mb\n")
        
        print(f"ğŸ” TensorProfiler ì´ˆê¸°í™”ë¨ - ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
    
    def log_tensor_size(self, tensor, name, tensor_type="activation"):
        """í…ì„œ ì‚¬ì´ì¦ˆë¥¼ ë¡œê¹…"""
        if tensor is None:
            return 0
            
        try:
            # í…ì„œ í¬ê¸° ê³„ì‚°
            size_bytes = self._calculate_tensor_size(tensor)
            size_mb = size_bytes / (1024 * 1024)
            
            # í˜•íƒœ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                shape = tensor.shape.as_list() if hasattr(tensor.shape, 'as_list') else list(tensor.shape)
            except:
                shape = "unknown"
            
            # í˜„ì¬ ìŠ¤í… í¬ê¸°ì— ì¶”ê°€
            self.current_step_size += size_bytes
            
            # Operationë³„ í¬ê¸° ì¶”ì 
            if name not in self.operation_tensor_sizes:
                self.operation_tensor_sizes[name] = []
            self.operation_tensor_sizes[name].append(size_bytes)
            
            # ìƒì„¸ ì •ë³´ ì €ì¥
            tensor_info = {
                'step': self.current_step,
                'operation': name,
                'tensor_type': tensor_type,
                'size_bytes': size_bytes,
                'size_mb': size_mb,
                'shape': shape
            }
            self.tensor_details.append(tensor_info)
            
            # íŒŒì¼ì— ì¦‰ì‹œ ë¡œê¹… (ë©”ëª¨ë¦¬ ì ˆì•½)
            self.tensor_log_file.write(f"{self.current_step},{name},{tensor_type},{size_bytes},{size_mb:.4f},{shape}\n")
            self.tensor_log_file.flush()
            
            return size_bytes
            
        except Exception as e:
            print(f"í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê¹… ì˜¤ë¥˜: {e}")
            return 0
    
    def log_gradients(self, gradients, variables):
        """ê·¸ë˜ë””ì–¸íŠ¸ í…ì„œë“¤ì˜ ì‚¬ì´ì¦ˆë¥¼ ë¡œê¹…"""
        for i, (grad, var) in enumerate(zip(gradients, variables)):
            if grad is not None:
                var_name = getattr(var, 'name', f'variable_{i}')
                self.log_tensor_size(grad, f"gradient_{var_name}", "gradient")
    
    def log_model_parameters(self, model):
        """ëª¨ë¸ íŒŒë¼ë¯¸í„°ë“¤ì˜ ì‚¬ì´ì¦ˆë¥¼ ë¡œê¹…"""
        total_params = 0
        trainable_params = 0
        
        for var in model.trainable_variables:
            param_size = self.log_tensor_size(var, f"param_{var.name}", "parameter")
            total_params += param_size
            trainable_params += param_size
        
        for var in model.non_trainable_variables:
            param_size = self.log_tensor_size(var, f"param_{var.name}", "parameter")
            total_params += param_size
        
        # íŒŒë¼ë¯¸í„° í†µê³„ ì €ì¥
        param_stats = {
            'step': self.current_step,
            'total_parameters_mb': total_params / (1024 * 1024),
            'trainable_parameters_mb': trainable_params / (1024 * 1024),
            'non_trainable_parameters_mb': (total_params - trainable_params) / (1024 * 1024)
        }
        self.parameter_sizes.append(param_stats)
        
        return param_stats
    
    def log_memory_usage(self):
        """GPU ë° CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ë¡œê¹…"""
        try:
            # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            gpu_memory = 0
            if tf.config.list_physical_devices('GPU'):
                try:
                    # TensorFlow GPU ë©”ëª¨ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    gpu_details = tf.config.experimental.get_memory_info('GPU:0')
                    gpu_memory = gpu_details['current'] / (1024 * 1024)  # MB ë‹¨ìœ„
                except:
                    # ëŒ€ì•ˆ ë°©ë²•
                    try:
                        import subprocess
                        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader'], 
                                              capture_output=True, text=True)
                        if result.returncode == 0:
                            gpu_memory = float(result.stdout.strip())
                    except:
                        gpu_memory = 0
            
            # CPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            cpu_memory = 0
            try:
                import psutil
                process = psutil.Process()
                cpu_memory = process.memory_info().rss / (1024 * 1024)  # MB ë‹¨ìœ„
            except:
                cpu_memory = 0
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì €ì¥
            memory_info = {
                'step': self.current_step,
                'gpu_memory_mb': gpu_memory,
                'cpu_memory_mb': cpu_memory
            }
            self.memory_usage.append(memory_info)
            
            # íŒŒì¼ì— ë¡œê¹…
            self.memory_log_file.write(f"{self.current_step},{gpu_memory:.2f},{cpu_memory:.2f}\n")
            self.memory_log_file.flush()
            
            return memory_info
            
        except Exception as e:
            print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹… ì˜¤ë¥˜: {e}")
            return {'step': self.current_step, 'gpu_memory_mb': 0, 'cpu_memory_mb': 0}
    
    def start_step(self, step):
        """ìƒˆë¡œìš´ ìŠ¤í… ì‹œì‘"""
        self.current_step = step
        self.current_step_size = 0
        print(f"ğŸ“Š Step {step} í…ì„œ í”„ë¡œíŒŒì¼ë§ ì‹œì‘")
    
    def end_step(self):
        """í˜„ì¬ ìŠ¤í… ì¢…ë£Œ ë° ê²°ê³¼ ì €ì¥"""
        step_size_mb = self.current_step_size / (1024 * 1024)
        self.step_tensor_sizes.append(step_size_mb)
        
        # ìš”ì•½ ì •ë³´ ì €ì¥
        num_ops = len([detail for detail in self.tensor_details if detail['step'] == self.current_step])
        avg_tensor_size = step_size_mb / num_ops if num_ops > 0 else 0
        
        # íŒŒì¼ì— ìš”ì•½ ì •ë³´ ë¡œê¹…
        self.summary_log_file.write(f"{self.current_step},{step_size_mb:.4f},{num_ops},{avg_tensor_size:.4f}\n")
        self.summary_log_file.flush()
        
        # Tiresias ìŠ¤íƒ€ì¼ í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê¹…
        self.tiresias_log_file.write(f"{self.current_step},{step_size_mb:.4f}\n")
        self.tiresias_log_file.flush()
        
        print(f"ğŸ“Š Step {self.current_step} ì™„ë£Œ - TensorSize: {step_size_mb:.2f} MB")
        
        return step_size_mb
    
    def get_tiresias_tensorsize(self):
        """Tiresias ë…¼ë¬¸ê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ í…ì„œ ì‚¬ì´ì¦ˆ ê³„ì‚°"""
        if len(self.step_tensor_sizes) == 0:
            return 0
        
        # ì²˜ìŒ ëª‡ ìŠ¤í…ì€ ì•ˆì •í™” ì‹œê°„ìœ¼ë¡œ ì œì™¸ (ì›Œë°ì—…)
        warmup_steps = min(3, len(self.step_tensor_sizes) // 4)
        stable_steps = self.step_tensor_sizes[warmup_steps:]
        
        if len(stable_steps) == 0:
            return np.mean(self.step_tensor_sizes) if self.step_tensor_sizes else 0
        
        # ì•ˆì •í™”ëœ ìŠ¤í…ë“¤ì˜ í‰ê· ìœ¼ë¡œ tensorsize ê³„ì‚°
        tiresias_tensorsize = np.mean(stable_steps)
        
        return tiresias_tensorsize
    
    def calculate_tensor_skewness(self):
        """ëª¨ë¸ í…ì„œ í¬ê¸°ë“¤ì˜ skewness(ì™œê³¡ë„) ê³„ì‚°"""
        try:
            # ëª¨ë“  í…ì„œ í¬ê¸°ë“¤ ìˆ˜ì§‘
            all_tensor_sizes = []
            
            for tensor_info in self.tensor_details:
                if tensor_info['size_bytes'] > 0:  # 0ë³´ë‹¤ í° í…ì„œë§Œ í¬í•¨
                    all_tensor_sizes.append(tensor_info['size_mb'])
            
            if len(all_tensor_sizes) < 3:  # skewness ê³„ì‚°ì„ ìœ„í•´ ìµœì†Œ 3ê°œ ë°ì´í„° í•„ìš”
                return 0.0
            
            # skewness ê³„ì‚° (scipy.stats.skew ì‚¬ìš©)
            tensor_skewness = stats.skew(all_tensor_sizes)
            
            return float(tensor_skewness)
            
        except Exception as e:
            print(f"Skewness ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0
    
    def calculate_operation_skewness(self):
        """Operationë³„ í…ì„œ í¬ê¸°ë“¤ì˜ skewness ê³„ì‚°"""
        try:
            operation_skewness = {}
            
            for op_name, sizes in self.operation_tensor_sizes.items():
                if len(sizes) >= 3:  # ìµœì†Œ 3ê°œ ë°ì´í„° í¬ì¸íŠ¸ í•„ìš”
                    sizes_mb = [size / (1024 * 1024) for size in sizes]
                    op_skewness = stats.skew(sizes_mb)
                    operation_skewness[op_name] = float(op_skewness)
            
            return operation_skewness
            
        except Exception as e:
            print(f"Operation skewness ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def calculate_layer_type_skewness(self):
        """ë ˆì´ì–´ íƒ€ì…ë³„ í…ì„œ í¬ê¸°ë“¤ì˜ skewness ê³„ì‚°"""
        try:
            # í…ì„œ íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
            type_sizes = {}
            
            for tensor_info in self.tensor_details:
                tensor_type = tensor_info['tensor_type']
                size_mb = tensor_info['size_mb']
                
                if tensor_type not in type_sizes:
                    type_sizes[tensor_type] = []
                
                if size_mb > 0:
                    type_sizes[tensor_type].append(size_mb)
            
            # ê° íƒ€ì…ë³„ skewness ê³„ì‚°
            type_skewness = {}
            for tensor_type, sizes in type_sizes.items():
                if len(sizes) >= 3:
                    type_skewness[tensor_type] = float(stats.skew(sizes))
            
            return type_skewness
            
        except Exception as e:
            print(f"Layer type skewness ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {}
    
    def get_skewness_summary(self):
        """ì „ì²´ skewness ë¶„ì„ ìš”ì•½"""
        try:
            # ì „ì²´ ëª¨ë¸ skewness
            model_skewness = self.calculate_tensor_skewness()
            
            # Operationë³„ skewness
            operation_skewness = self.calculate_operation_skewness()
            
            # ë ˆì´ì–´ íƒ€ì…ë³„ skewness
            layer_type_skewness = self.calculate_layer_type_skewness()
            
            # í†µê³„ ì •ë³´
            all_tensor_sizes = [info['size_mb'] for info in self.tensor_details if info['size_mb'] > 0]
            
            skewness_summary = {
                'model_skewness': model_skewness,
                'operation_skewness': operation_skewness,
                'layer_type_skewness': layer_type_skewness,
                'tensor_count': len(all_tensor_sizes),
                'mean_tensor_size_mb': np.mean(all_tensor_sizes) if all_tensor_sizes else 0,
                'std_tensor_size_mb': np.std(all_tensor_sizes) if all_tensor_sizes else 0,
                'min_tensor_size_mb': np.min(all_tensor_sizes) if all_tensor_sizes else 0,
                'max_tensor_size_mb': np.max(all_tensor_sizes) if all_tensor_sizes else 0
            }
            
            return skewness_summary
            
        except Exception as e:
            print(f"Skewness ìš”ì•½ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return {'model_skewness': 0.0}
    
    def log_skewness_analysis(self):
        """Skewness ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ì— ë¡œê¹…"""
        try:
            skewness_summary = self.get_skewness_summary()
            
            # Skewness ë¶„ì„ ë¡œê·¸ íŒŒì¼
            skewness_log_file = os.path.join(self.log_dir, 'skewness_analysis.txt')
            with open(skewness_log_file, 'w') as f:
                f.write("=== Tensor Skewness Analysis ===\n")
                f.write(f"Model Skewness: {skewness_summary['model_skewness']:.2f}\n")
                f.write(f"Total Tensors: {skewness_summary['tensor_count']}\n")
                f.write(f"Mean Tensor Size: {skewness_summary['mean_tensor_size_mb']:.4f} MB\n")
                f.write(f"Std Tensor Size: {skewness_summary['std_tensor_size_mb']:.4f} MB\n")
                f.write(f"Min Tensor Size: {skewness_summary['min_tensor_size_mb']:.4f} MB\n")
                f.write(f"Max Tensor Size: {skewness_summary['max_tensor_size_mb']:.4f} MB\n")
                f.write("\n=== Layer Type Skewness ===\n")
                
                for layer_type, skewness in skewness_summary['layer_type_skewness'].items():
                    f.write(f"{layer_type}: {skewness:.2f}\n")
                
                f.write("\n=== Top 10 Operation Skewness ===\n")
                op_skewness = skewness_summary['operation_skewness']
                sorted_ops = sorted(op_skewness.items(), key=lambda x: abs(x[1]), reverse=True)[:10]
                
                for op_name, skewness in sorted_ops:
                    f.write(f"{op_name}: {skewness:.2f}\n")
            
            # JSON í˜•íƒœë¡œë„ ì €ì¥
            with open(os.path.join(self.log_dir, 'skewness_analysis.json'), 'w') as f:
                json.dump(skewness_summary, f, indent=2, default=str)
            
            return skewness_summary
            
        except Exception as e:
            print(f"Skewness ë¡œê¹… ì˜¤ë¥˜: {e}")
            return {'model_skewness': 0.0}
    
    def get_summary(self):
        """ì „ì²´ í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ìš”ì•½"""
        if not self.step_tensor_sizes:
            return {}
        
        tiresias_tensorsize = self.get_tiresias_tensorsize()
        
        # Skewness ë¶„ì„ ì¶”ê°€
        skewness_summary = self.get_skewness_summary()
        
        summary = {
            'total_steps': len(self.step_tensor_sizes),
            'tiresias_tensorsize_mb': tiresias_tensorsize,
            'avg_step_tensorsize_mb': np.mean(self.step_tensor_sizes),
            'max_step_tensorsize_mb': np.max(self.step_tensor_sizes),
            'min_step_tensorsize_mb': np.min(self.step_tensor_sizes),
            'std_step_tensorsize_mb': np.std(self.step_tensor_sizes),
            'total_operations': len(self.tensor_details),
            'step_tensor_sizes': self.step_tensor_sizes,
            'model_skewness': skewness_summary['model_skewness'],  # ì¶”ê°€
            'skewness_analysis': skewness_summary  # ì¶”ê°€
        }
        
        # Operationë³„ í†µê³„
        op_stats = {}
        for op_name, sizes in self.operation_tensor_sizes.items():
            op_stats[op_name] = {
                'total_size_mb': sum(sizes) / (1024 * 1024),
                'avg_size_mb': np.mean(sizes) / (1024 * 1024),
                'count': len(sizes)
            }
        
        summary['operation_stats'] = op_stats
        
        return summary
    
    def save_final_results(self):
        """ìµœì¢… ê²°ê³¼ë¥¼ íŒŒì¼ì— ì €ì¥"""
        summary = self.get_summary()
        
        # JSON í˜•íƒœë¡œ ì €ì¥
        with open(os.path.join(self.log_dir, 'final_summary.json'), 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        
        # Tiresias ê²°ê³¼ ì €ì¥
        tiresias_result = {
            'model': 'whisper_small',
            'tensorsize_mb': summary['tiresias_tensorsize_mb'],
            'skewness': summary['model_skewness'],  # ì¶”ê°€
            'total_steps': summary['total_steps'],
            'measurement_method': 'Tiresias_style'
        }
        
        with open(os.path.join(self.log_dir, 'tiresias_result.json'), 'w') as f:
            json.dump(tiresias_result, f, indent=2)
        
        # ë ˆê±°ì‹œ í¬ë§·ìœ¼ë¡œ skewness ê²°ê³¼ ì €ì¥
        with open(os.path.join(self.log_dir, 'legacy_skewness_result.txt'), 'w') as f:
            f.write("model,skewness\n")
            f.write(f"whisper_small,{summary['model_skewness']:.1f}\n")
        
        # Skewness ë¶„ì„ ë¡œê¹…
        self.log_skewness_analysis()
        
        return summary
    
    def _calculate_tensor_size(self, tensor):
        """í…ì„œì˜ ë©”ëª¨ë¦¬ ì‚¬ì´ì¦ˆë¥¼ ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ê³„ì‚°"""
        try:
            if tensor is None:
                return 0
            
            # í…ì„œì˜ ëª¨ë“  ìš”ì†Œ ê°œìˆ˜ ê³„ì‚°
            if hasattr(tensor, 'shape'):
                total_elements = tf.size(tensor).numpy() if hasattr(tf.size(tensor), 'numpy') else 1
                for dim in tensor.shape:
                    if dim is not None:
                        total_elements = total_elements if hasattr(tf.size(tensor), 'numpy') else total_elements * int(dim)
            else:
                total_elements = 1
            
            # ë°ì´í„° íƒ€ì…ë³„ ë°”ì´íŠ¸ í¬ê¸°
            dtype_size = tensor.dtype.size if hasattr(tensor, 'dtype') else 4  # ê¸°ë³¸ê°’ 4ë°”ì´íŠ¸
            
            return int(total_elements * dtype_size)
        except Exception as e:
            print(f"í…ì„œ í¬ê¸° ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0
    
    def close(self):
        """í”„ë¡œíŒŒì¼ëŸ¬ ì¢…ë£Œ ë° íŒŒì¼ ë‹«ê¸°"""
        try:
            self.tensor_log_file.close()
            self.memory_log_file.close()
            self.summary_log_file.close()
            self.tiresias_log_file.close()
            print(f"ğŸ” TensorProfiler ì¢…ë£Œë¨")
        except:
            pass


class TensorLoggingMixin:
    """ë ˆì´ì–´ì— í…ì„œ ë¡œê¹… ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ë¯¹ìŠ¤ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.profiler = None
    
    def set_profiler(self, profiler):
        """í”„ë¡œíŒŒì¼ëŸ¬ ì„¤ì •"""
        self.profiler = profiler
    
    def log_tensor_if_profiler(self, tensor, name, tensor_type="activation"):
        """í”„ë¡œíŒŒì¼ëŸ¬ê°€ ì„¤ì •ëœ ê²½ìš° í…ì„œ ë¡œê¹…"""
        if self.profiler is not None:
            return self.profiler.log_tensor_size(tensor, name, tensor_type)
        return 0


class TensorSizeMonitor:
    """í…ì„œ ì‚¬ì´ì¦ˆë¥¼ ëª¨ë‹ˆí„°ë§í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.current_step_size = 0
        self.total_size = 0
        self.op_sizes = {}
    
    def calculate_tensor_size(self, tensor):
        """í…ì„œì˜ ë©”ëª¨ë¦¬ ì‚¬ì´ì¦ˆë¥¼ ë°”ì´íŠ¸ ë‹¨ìœ„ë¡œ ê³„ì‚°"""
        if tensor is None:
            return 0
        
        try:
            # í…ì„œì˜ shapeê³¼ dtypeì„ ì´ìš©í•´ ë©”ëª¨ë¦¬ ì‚¬ì´ì¦ˆ ê³„ì‚°
            shape = tf.shape(tensor).numpy() if hasattr(tf.shape(tensor), 'numpy') else tensor.shape
            dtype_size = tensor.dtype.size
            
            total_elements = 1
            for dim in shape:
                total_elements *= int(dim)
            
            return total_elements * dtype_size
        except:
            # shapeì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš° ì¶”ì •
            try:
                return tf.size(tensor).numpy() * tensor.dtype.size
            except:
                return 0
    
    def track_tensor(self, tensor, operation_name="unknown"):
        """í…ì„œë¥¼ ì¶”ì í•˜ê³  ì‚¬ì´ì¦ˆë¥¼ ê¸°ë¡"""
        size = self.calculate_tensor_size(tensor)
        
        if operation_name not in self.op_sizes:
            self.op_sizes[operation_name] = []
        
        self.op_sizes[operation_name].append(size)
        self.current_step_size += size
        
        return size
    
    def reset_step(self):
        """ìŠ¤í… ì´ˆê¸°í™”"""
        self.current_step_size = 0
    
    def get_step_summary(self):
        """í˜„ì¬ ìŠ¤í…ì˜ í…ì„œ ì‚¬ì´ì¦ˆ ìš”ì•½"""
        return {
            'step_total_size': self.current_step_size,
            'operation_sizes': {op: sum(sizes) for op, sizes in self.op_sizes.items()}
        }


# ì „ì—­ í…ì„œ ëª¨ë‹ˆí„°
tensor_monitor = TensorSizeMonitor()


class WhisperConfig:
    def __init__(self):
        # ëª¨ë¸ í¬ê¸° ì„¤ì • (Whisper-small ê¸°ì¤€)
        self.d_model = 768  # ëª¨ë¸ ì°¨ì›
        self.encoder_layers = 4  # ì¸ì½”ë” ë ˆì´ì–´ ìˆ˜
        self.encoder_attention_heads = 12  # ì¸ì½”ë” ì–´í…ì…˜ í—¤ë“œ ìˆ˜
        self.decoder_layers = 4  # ë””ì½”ë” ë ˆì´ì–´ ìˆ˜
        self.decoder_attention_heads = 12  # ë””ì½”ë” ì–´í…ì…˜ í—¤ë“œ ìˆ˜
        self.d_ff = 3072  # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ì°¨ì›
        
        # ì¸ì½”ë” ì„¤ì •
        self.n_mels = 80  # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ íŠ¹ì§• ìˆ˜
        self.n_ctx = 1500  # ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ (30ì´ˆ ì˜¤ë””ì˜¤)
        
        # ë””ì½”ë” ì„¤ì •
        self.vocab_size = 51865  # ì „ì²´ ì–´íœ˜ í¬ê¸°
        self.max_target_positions = 448  # ìµœëŒ€ ì¶œë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´
        
        # í•™ìŠµ ê´€ë ¨ ì„¤ì •
        self.dropout = 0.1
        self.attention_dropout = 0.1
        self.activation_dropout = 0.0
        self.activation_function = "gelu"
        
        # ê¸°íƒ€ ì„¤ì •
        self.layer_norm_eps = 1e-5
        self.init_std = 0.02
        
        # íŠ¹ìˆ˜ í† í° ì„¤ì •
        self.pad_token_id = 0
        self.bos_token_id = 1
        self.eos_token_id = 2
        
        # ì¶”ê°€ ì„¤ì •
        self.use_cache = True
        self.decoder_start_token_id = 50257  # <|startoftranscript|>


# ìœ„ì¹˜ ì¸ì½”ë”©
class PositionalEncoding(tf.keras.layers.Layer, TensorLoggingMixin):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.d_model = d_model
        
        # ìœ„ì¹˜ ì¸ì½”ë”© í–‰ë ¬ ê³„ì‚°
        pe = np.zeros((max_len, d_model))
        position = np.arange(0, max_len)[:, np.newaxis]
        div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))
        
        # ì§ìˆ˜ ì¸ë±ìŠ¤ì—ëŠ” sin, í™€ìˆ˜ ì¸ë±ìŠ¤ì—ëŠ” cos
        pe[:, 0::2] = np.sin(position * div_term)
        pe[:, 1::2] = np.cos(position * div_term)
        
        self.pe = tf.convert_to_tensor(pe, dtype=tf.float32)
        self.pe = tf.expand_dims(self.pe, 0)  # [1, max_len, d_model]
    
    def call(self, x):
        # x: [batch_size, seq_len, d_model]
        self.log_tensor_if_profiler(x, "positional_encoding_input")
        tensor_monitor.track_tensor(x, "positional_encoding_input")
        seq_len = tf.shape(x)[1]
        result = x + self.pe[:, :seq_len, :]
        self.log_tensor_if_profiler(result, "positional_encoding_output")
        tensor_monitor.track_tensor(result, "positional_encoding_output")
        return result


# ë©€í‹°í—¤ë“œ ì–´í…ì…˜ êµ¬í˜„
class MultiHeadAttention(tf.keras.layers.Layer, TensorLoggingMixin):
    def __init__(self, config, is_decoder=False, is_cross_attention=False):
        super(MultiHeadAttention, self).__init__()
        self.is_decoder = is_decoder
        self.is_cross_attention = is_cross_attention
        
        if is_decoder:
            self.num_heads = config.decoder_attention_heads
            self.d_model = config.d_model
        else:
            self.num_heads = config.encoder_attention_heads
            self.d_model = config.d_model
            
        self.head_dim = self.d_model // self.num_heads
        self.scaling = self.head_dim ** -0.5
        
        self.k_proj = tf.keras.layers.Dense(self.d_model, use_bias=True)
        self.v_proj = tf.keras.layers.Dense(self.d_model, use_bias=True)
        self.q_proj = tf.keras.layers.Dense(self.d_model, use_bias=True)
        self.out_proj = tf.keras.layers.Dense(self.d_model, use_bias=True)
        
        self.dropout = tf.keras.layers.Dropout(config.attention_dropout)
    
    def _reshape(self, x):
        batch_size = tf.shape(x)[0]
        seq_len = tf.shape(x)[1]
        
        # [batch_size, seq_len, d_model] -> [batch_size, seq_len, num_heads, head_dim]
        x = tf.reshape(x, (batch_size, seq_len, self.num_heads, self.head_dim))
        
        # [batch_size, seq_len, num_heads, head_dim] -> [batch_size, num_heads, seq_len, head_dim]
        return tf.transpose(x, perm=[0, 2, 1, 3])
    
    def call(self, hidden_states, key_value_states=None, attention_mask=None, 
             past_key_value=None, layer_head_mask=None, training=False):
        """
        hidden_states: ì¿¼ë¦¬ í…ì„œ [batch_size, seq_len, d_model]
        key_value_states: í‚¤/ê°’ í…ì„œ (cross-attention ì‚¬ìš© ì‹œ) [batch_size, kv_seq_len, d_model]
        attention_mask: ì–´í…ì…˜ ë§ˆìŠ¤í¬ [batch_size, seq_len, kv_seq_len]
        past_key_value: ìºì‹±ëœ í‚¤/ê°’ (ë””ì½”ë”ì—ì„œ ì‚¬ìš©)
        """
        self.log_tensor_if_profiler(hidden_states, "attention_hidden_states_input")
        tensor_monitor.track_tensor(hidden_states, "attention_hidden_states_input")
        
        batch_size = tf.shape(hidden_states)[0]
        seq_len = tf.shape(hidden_states)[1]
        
        # cross-attentionì¸ ê²½ìš° key, valueëŠ” ì¸ì½”ë” ì¶œë ¥, queryëŠ” ë””ì½”ë” ìƒíƒœ
        is_cross_attention = key_value_states is not None
        
        if is_cross_attention:
            # cross-attentionì¸ ê²½ìš° key_value_statesì—ì„œ keyì™€ value ì¶”ì¶œ
            key_states = self._reshape(self.k_proj(key_value_states))  # [batch, num_heads, kv_seq_len, head_dim]
            value_states = self._reshape(self.v_proj(key_value_states))  # [batch, num_heads, kv_seq_len, head_dim]
            self.log_tensor_if_profiler(key_states, "cross_attention_key_states")
            self.log_tensor_if_profiler(value_states, "cross_attention_value_states")
            tensor_monitor.track_tensor(key_states, "cross_attention_key_states")
            tensor_monitor.track_tensor(value_states, "cross_attention_value_states")
            kv_seq_len = tf.shape(key_states)[2]
        elif past_key_value is not None:
            # ê³¼ê±° í‚¤/ê°’ì´ ìˆëŠ” ê²½ìš° (ë””ì½”ë”ì˜ auto-regressive ìƒì„± ì‹œ)
            key_states = self._reshape(self.k_proj(hidden_states))  # [batch, num_heads, seq_len, head_dim]
            value_states = self._reshape(self.v_proj(hidden_states))  # [batch, num_heads, seq_len, head_dim]
            
            # ê³¼ê±° í‚¤/ê°’ê³¼ í˜„ì¬ í‚¤/ê°’ ì—°ê²°
            key_states = tf.concat([past_key_value[0], key_states], axis=2)
            value_states = tf.concat([past_key_value[1], value_states], axis=2)
            self.log_tensor_if_profiler(key_states, "past_key_states")
            self.log_tensor_if_profiler(value_states, "past_value_states")
            tensor_monitor.track_tensor(key_states, "past_key_states")
            tensor_monitor.track_tensor(value_states, "past_value_states")
            kv_seq_len = tf.shape(key_states)[2]
        else:
            # ì¼ë°˜ì ì¸ self-attention
            key_states = self._reshape(self.k_proj(hidden_states))  # [batch, num_heads, seq_len, head_dim]
            value_states = self._reshape(self.v_proj(hidden_states))  # [batch, num_heads, seq_len, head_dim]
            self.log_tensor_if_profiler(key_states, "self_attention_key_states")
            self.log_tensor_if_profiler(value_states, "self_attention_value_states")
            tensor_monitor.track_tensor(key_states, "self_attention_key_states")
            tensor_monitor.track_tensor(value_states, "self_attention_value_states")
            kv_seq_len = seq_len
        
        # í•­ìƒ ì¿¼ë¦¬ëŠ” í˜„ì¬ hidden_statesì—ì„œ ê³„ì‚°
        query_states = self._reshape(self.q_proj(hidden_states) * self.scaling)  # [batch, num_heads, seq_len, head_dim]
        self.log_tensor_if_profiler(query_states, "attention_query_states")
        tensor_monitor.track_tensor(query_states, "attention_query_states")
        
        # í˜„ì¬ í‚¤/ê°’ ì €ì¥ (ë””ì½”ë”ì—ì„œ ìºì‹± ì‹œ ì‚¬ìš©)
        past_key_value = (key_states, value_states) if self.is_decoder else None
        
        # ì–´í…ì…˜ ìŠ¤ì½”ì–´ ê³„ì‚°: [batch, num_heads, seq_len, kv_seq_len]
        attention_scores = tf.matmul(query_states, key_states, transpose_b=True)
        self.log_tensor_if_profiler(attention_scores, "attention_scores")
        tensor_monitor.track_tensor(attention_scores, "attention_scores")
        
        # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ì ìš© (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
        if attention_mask is not None:
            # ë§ˆìŠ¤í¬ í™•ì¥ ë° ì ìš© (ë§ˆìŠ¤í¬ê°€ 0ì¸ ìœ„ì¹˜ëŠ” -infë¡œ ì„¤ì •)
            attention_mask = tf.cast(attention_mask, tf.float32)
            attention_mask = (1.0 - attention_mask) * -1e9
            attention_scores = attention_scores + attention_mask
            self.log_tensor_if_profiler(attention_mask, "attention_mask")
            tensor_monitor.track_tensor(attention_mask, "attention_mask")
        
        # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©
        attention_probs = tf.nn.softmax(attention_scores, axis=-1)
        self.log_tensor_if_profiler(attention_probs, "attention_probs")
        tensor_monitor.track_tensor(attention_probs, "attention_probs")
        
        # ë“œë¡­ì•„ì›ƒ ì ìš©
        attention_probs = self.dropout(attention_probs, training=training)
        
        # í—¤ë“œ ë§ˆìŠ¤í¬ ì ìš© (í•„ìš”í•œ ê²½ìš°)
        if layer_head_mask is not None:
            attention_probs = attention_probs * tf.expand_dims(tf.expand_dims(layer_head_mask, -1), -1)
        
        # ì–´í…ì…˜ ì¶œë ¥ ê³„ì‚°
        attention_output = tf.matmul(attention_probs, value_states)  # [batch, num_heads, seq_len, head_dim]
        self.log_tensor_if_profiler(attention_output, "attention_output_raw")
        tensor_monitor.track_tensor(attention_output, "attention_output_raw")
        
        # ì¶œë ¥ í˜•íƒœ ë³€í™˜
        attention_output = tf.transpose(attention_output, perm=[0, 2, 1, 3])  # [batch, seq_len, num_heads, head_dim]
        attention_output = tf.reshape(attention_output, (batch_size, seq_len, self.d_model))  # [batch, seq_len, d_model]
        
        # ìµœì¢… ì„ í˜• ë³€í™˜
        attention_output = self.out_proj(attention_output)
        self.log_tensor_if_profiler(attention_output, "attention_output_final")
        tensor_monitor.track_tensor(attention_output, "attention_output_final")
        
        return attention_output, attention_probs, past_key_value


# í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬
class FeedForward(tf.keras.layers.Layer, TensorLoggingMixin):
    def __init__(self, config, is_decoder=False):
        super(FeedForward, self).__init__()
        if is_decoder:
            d_model = config.d_model
            d_ff = config.d_ff
            dropout = config.dropout
            activation_dropout = config.activation_dropout
        else:
            d_model = config.d_model
            d_ff = config.d_ff
            dropout = config.dropout
            activation_dropout = config.activation_dropout
        
        self.fc1 = tf.keras.layers.Dense(d_ff, use_bias=True)
        self.activation_fn = tf.keras.activations.gelu
        self.activation_dropout = tf.keras.layers.Dropout(activation_dropout)
        self.fc2 = tf.keras.layers.Dense(d_model, use_bias=True)
        self.dropout = tf.keras.layers.Dropout(dropout)
    
    def call(self, hidden_states, training=False):
        self.log_tensor_if_profiler(hidden_states, "feedforward_input")
        tensor_monitor.track_tensor(hidden_states, "feedforward_input")
        
        hidden_states = self.fc1(hidden_states)
        self.log_tensor_if_profiler(hidden_states, "feedforward_fc1_output")
        tensor_monitor.track_tensor(hidden_states, "feedforward_fc1_output")
        
        hidden_states = self.activation_fn(hidden_states)
        self.log_tensor_if_profiler(hidden_states, "feedforward_activation_output")
        tensor_monitor.track_tensor(hidden_states, "feedforward_activation_output")
        
        hidden_states = self.activation_dropout(hidden_states, training=training)
        hidden_states = self.fc2(hidden_states)
        self.log_tensor_if_profiler(hidden_states, "feedforward_fc2_output")
        tensor_monitor.track_tensor(hidden_states, "feedforward_fc2_output")
        
        hidden_states = self.dropout(hidden_states, training=training)
        self.log_tensor_if_profiler(hidden_states, "feedforward_final_output")
        tensor_monitor.track_tensor(hidden_states, "feedforward_final_output")
        
        return hidden_states


# ì¸ì½”ë” ë ˆì´ì–´
class WhisperEncoderLayer(tf.keras.layers.Layer):
    def __init__(self, config):
        super(WhisperEncoderLayer, self).__init__()
        self.self_attn = MultiHeadAttention(config, is_decoder=False)
        self.self_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
        self.feed_forward = FeedForward(config, is_decoder=False)
        self.final_layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
    
    def call(self, hidden_states, attention_mask=None, layer_head_mask=None, training=False):
        tensor_monitor.track_tensor(hidden_states, "encoder_layer_input")
        
        # Self Attention
        residual = hidden_states
        tensor_monitor.track_tensor(residual, "encoder_residual_1")
        
        hidden_states = self.self_attn_layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "encoder_layer_norm_1")
        
        attention_output, attention_weights, _ = self.self_attn(
            hidden_states=hidden_states,
            attention_mask=attention_mask,
            layer_head_mask=layer_head_mask,
            training=training
        )
        hidden_states = residual + attention_output
        tensor_monitor.track_tensor(hidden_states, "encoder_after_attention")
        
        # Feed Forward
        residual = hidden_states
        tensor_monitor.track_tensor(residual, "encoder_residual_2")
        
        hidden_states = self.final_layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "encoder_layer_norm_2")
        
        feed_forward_output = self.feed_forward(hidden_states, training=training)
        hidden_states = residual + feed_forward_output
        tensor_monitor.track_tensor(hidden_states, "encoder_layer_output")
        
        return hidden_states, attention_weights


# ë””ì½”ë” ë ˆì´ì–´
class WhisperDecoderLayer(tf.keras.layers.Layer):
    def __init__(self, config):
        super(WhisperDecoderLayer, self).__init__()
        # Self Attention
        self.self_attn = MultiHeadAttention(config, is_decoder=True)
        self.self_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
        
        # Cross Attention
        self.encoder_attn = MultiHeadAttention(config, is_decoder=True, is_cross_attention=True)
        self.encoder_attn_layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
        
        # Feed Forward
        self.feed_forward = FeedForward(config, is_decoder=True)
        self.final_layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
    
    def call(self, hidden_states, encoder_hidden_states, 
             attention_mask=None, encoder_attention_mask=None,
             layer_head_mask=None, cross_attn_layer_head_mask=None,
             past_key_value=None, training=False):
        
        tensor_monitor.track_tensor(hidden_states, "decoder_layer_input")
        tensor_monitor.track_tensor(encoder_hidden_states, "decoder_encoder_hidden_states")
        
        # ìºì‹œëœ ê³¼ê±° í‚¤/ê°’ ë¶„ë¦¬
        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None
        cross_attn_past_key_value = past_key_value[2:] if past_key_value is not None else None
        
        # Self Attention
        residual = hidden_states
        tensor_monitor.track_tensor(residual, "decoder_residual_1")
        
        hidden_states = self.self_attn_layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "decoder_layer_norm_1")
        
        attention_output, self_attention_weights, present_key_value = self.self_attn(
            hidden_states=hidden_states,
            attention_mask=attention_mask,
            layer_head_mask=layer_head_mask,
            past_key_value=self_attn_past_key_value,
            training=training
        )
        
        hidden_states = residual + attention_output
        tensor_monitor.track_tensor(hidden_states, "decoder_after_self_attention")
        
        # Cross Attention
        residual = hidden_states
        tensor_monitor.track_tensor(residual, "decoder_residual_2")
        
        hidden_states = self.encoder_attn_layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "decoder_layer_norm_2")
        
        cross_attention_output, cross_attention_weights, cross_attn_present_key_value = self.encoder_attn(
            hidden_states=hidden_states,
            key_value_states=encoder_hidden_states,
            attention_mask=encoder_attention_mask,
            layer_head_mask=cross_attn_layer_head_mask,
            training=training
        )
        
        hidden_states = residual + cross_attention_output
        tensor_monitor.track_tensor(hidden_states, "decoder_after_cross_attention")
        
        # Feed Forward
        residual = hidden_states
        tensor_monitor.track_tensor(residual, "decoder_residual_3")
        
        hidden_states = self.final_layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "decoder_layer_norm_3")
        
        feed_forward_output = self.feed_forward(hidden_states, training=training)
        hidden_states = residual + feed_forward_output
        tensor_monitor.track_tensor(hidden_states, "decoder_layer_output")
        
        # í˜„ì¬ ë ˆì´ì–´ì˜ í‚¤/ê°’ ëª¨ìŒ
        present_key_value = present_key_value + cross_attn_present_key_value if present_key_value is not None else None
        
        return hidden_states, self_attention_weights, cross_attention_weights, present_key_value


# ì˜¤ë””ì˜¤ ì¸ì½”ë”
class WhisperEncoder(tf.keras.layers.Layer):
    def __init__(self, config):
        super(WhisperEncoder, self).__init__()
        self.config = config
        
        # ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ ë° ì„ë² ë”©
        self.conv1 = tf.keras.layers.Conv1D(config.d_model, kernel_size=3, strides=1, padding="same")
        self.conv2 = tf.keras.layers.Conv1D(config.d_model, kernel_size=3, strides=2, padding="same")
        self.positional_embedding = PositionalEncoding(config.d_model, config.n_ctx)
        
        # ë“œë¡­ì•„ì›ƒ
        self.dropout = tf.keras.layers.Dropout(config.dropout)
        
        # ì¸ì½”ë” ë ˆì´ì–´
        self.layers = [WhisperEncoderLayer(config) for _ in range(config.encoder_layers)]
        
        # ë ˆì´ì–´ ì •ê·œí™”
        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
    
    def call(self, input_features, attention_mask=None, layer_head_mask=None, training=False):
        """
        input_features: ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ íŠ¹ì§• [batch_size, n_mels, seq_len]
        """
        tensor_monitor.track_tensor(input_features, "encoder_input_features")
        
        # ì°¨ì› ë³€í™˜ (ì±„ë„ ë§ˆì§€ë§‰)
        input_features = tf.transpose(input_features, perm=[0, 2, 1])  # [batch, seq_len, n_mels]
        tensor_monitor.track_tensor(input_features, "encoder_transposed_features")
        
        # ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì ìš©
        hidden_states = self.conv1(input_features)
        tensor_monitor.track_tensor(hidden_states, "encoder_conv1_output")
        
        hidden_states = tf.keras.activations.gelu(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "encoder_conv1_gelu")
        
        hidden_states = self.conv2(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "encoder_conv2_output")
        
        hidden_states = tf.keras.activations.gelu(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "encoder_conv2_gelu")
        
        # ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€
        hidden_states = self.positional_embedding(hidden_states)
        
        # ë“œë¡­ì•„ì›ƒ
        hidden_states = self.dropout(hidden_states, training=training)
        tensor_monitor.track_tensor(hidden_states, "encoder_after_dropout")
        
        # ë ˆì´ì–´ë³„ ì²˜ë¦¬
        all_hidden_states = ()
        all_self_attentions = ()
        
        for i, layer in enumerate(self.layers):
            all_hidden_states = all_hidden_states + (hidden_states,)
            
            # ë ˆì´ì–´ í—¤ë“œ ë§ˆìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
            layer_head_mask_i = layer_head_mask[i] if layer_head_mask is not None else None
            
            # ë ˆì´ì–´ í˜¸ì¶œ
            hidden_states, self_attn_weights = layer(
                hidden_states,
                attention_mask=attention_mask,
                layer_head_mask=layer_head_mask_i,
                training=training
            )
            
            all_self_attentions = all_self_attentions + (self_attn_weights,)
            tensor_monitor.track_tensor(hidden_states, f"encoder_layer_{i}_output")
        
        # ìµœì¢… ë ˆì´ì–´ ì •ê·œí™”
        hidden_states = self.layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "encoder_final_output")
        
        # ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "last_hidden_state": hidden_states,
            "hidden_states": all_hidden_states,
            "attentions": all_self_attentions
        }


# í…ìŠ¤íŠ¸ ë””ì½”ë”
class WhisperDecoder(tf.keras.layers.Layer):
    def __init__(self, config):
        super(WhisperDecoder, self).__init__()
        self.config = config
        
        # í† í° ì„ë² ë”©
        self.embed_tokens = tf.keras.layers.Embedding(config.vocab_size, config.d_model)
        self.positional_embedding = PositionalEncoding(config.d_model, config.max_target_positions)
        
        # ë“œë¡­ì•„ì›ƒ
        self.dropout = tf.keras.layers.Dropout(config.dropout)
        
        # ë””ì½”ë” ë ˆì´ì–´
        self.layers = [WhisperDecoderLayer(config) for _ in range(config.decoder_layers)]
        
        # ë ˆì´ì–´ ì •ê·œí™”
        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps)
    
    def call(self, input_ids, encoder_hidden_states,
             attention_mask=None, encoder_attention_mask=None,
             layer_head_mask=None, cross_attn_layer_head_mask=None,
             past_key_values=None, use_cache=False, training=False):
        """
        input_ids: ì…ë ¥ í† í° ID [batch_size, seq_len]
        encoder_hidden_states: ì¸ì½”ë” ì¶œë ¥ [batch_size, enc_seq_len, d_model]
        """
        tensor_monitor.track_tensor(input_ids, "decoder_input_ids")
        
        batch_size, seq_length = tf.shape(input_ids)[0], tf.shape(input_ids)[1]
        
        # ì…ë ¥ í† í° ì„ë² ë”©
        inputs_embeds = self.embed_tokens(input_ids)
        tensor_monitor.track_tensor(inputs_embeds, "decoder_token_embeddings")
        
        # ìœ„ì¹˜ ì¸ì½”ë”© ì¶”ê°€
        hidden_states = self.positional_embedding(inputs_embeds)
        
        # ë“œë¡­ì•„ì›ƒ
        hidden_states = self.dropout(hidden_states, training=training)
        tensor_monitor.track_tensor(hidden_states, "decoder_after_dropout")
        
        # ì–´í…ì…˜ ë§ˆìŠ¤í¬ í™•ì¸ ë° ìƒì„±
        if attention_mask is None:
            # ì¸ê³¼ì  ë§ˆìŠ¤í¬ ìƒì„± (ìê¸° ìì‹ ê³¼ ì´ì „ ìœ„ì¹˜ë§Œ ë³¼ ìˆ˜ ìˆìŒ)
            attention_mask = 1.0 - tf.linalg.band_part(
                tf.ones((seq_length, seq_length)), -1, 0)
            attention_mask = tf.expand_dims(attention_mask, 0)  # [1, seq_len, seq_len]
            tensor_monitor.track_tensor(attention_mask, "decoder_causal_mask")
        
        # ì´ˆê¸°í™”
        all_hidden_states = ()
        all_self_attentions = ()
        all_cross_attentions = ()
        present_key_values = () if use_cache else None
        
        # ë ˆì´ì–´ë³„ ì²˜ë¦¬
        for i, layer in enumerate(self.layers):
            all_hidden_states = all_hidden_states + (hidden_states,)
            
            # ê³¼ê±° í‚¤/ê°’ ê°€ì ¸ì˜¤ê¸°
            past_key_value = past_key_values[i] if past_key_values is not None else None
            
            # ë§ˆìŠ¤í¬ ê°€ì ¸ì˜¤ê¸°
            layer_head_mask_i = layer_head_mask[i] if layer_head_mask is not None else None
            cross_attn_layer_head_mask_i = cross_attn_layer_head_mask[i] if cross_attn_layer_head_mask is not None else None
            
            # ë ˆì´ì–´ í˜¸ì¶œ
            hidden_states, self_attn_weights, cross_attn_weights, present_key_value = layer(
                hidden_states,
                encoder_hidden_states=encoder_hidden_states,
                attention_mask=attention_mask,
                encoder_attention_mask=encoder_attention_mask,
                layer_head_mask=layer_head_mask_i,
                cross_attn_layer_head_mask=cross_attn_layer_head_mask_i,
                past_key_value=past_key_value,
                training=training
            )
            
            # ê²°ê³¼ ì €ì¥
            all_self_attentions = all_self_attentions + (self_attn_weights,)
            all_cross_attentions = all_cross_attentions + (cross_attn_weights,)
            
            tensor_monitor.track_tensor(hidden_states, f"decoder_layer_{i}_output")
            
            if use_cache:
                present_key_values = present_key_values + (present_key_value,)
        
        # ìµœì¢… ë ˆì´ì–´ ì •ê·œí™”
        hidden_states = self.layer_norm(hidden_states)
        tensor_monitor.track_tensor(hidden_states, "decoder_final_output")
        
        # ê²°ê³¼ ë°˜í™˜
        return {
            "last_hidden_state": hidden_states,
            "past_key_values": present_key_values,
            "hidden_states": all_hidden_states,
            "attentions": all_self_attentions,
            "cross_attentions": all_cross_attentions
        }


# ì „ì²´ Whisper ëª¨ë¸
class WhisperModel(tf.keras.Model):
    def __init__(self, config):
        super(WhisperModel, self).__init__()
        self.config = config
        
        # ì¸ì½”ë”ì™€ ë””ì½”ë” ì´ˆê¸°í™”
        self.encoder = WhisperEncoder(config)
        self.decoder = WhisperDecoder(config)
    
    def call(self, input_features, decoder_input_ids=None,
             attention_mask=None, decoder_attention_mask=None,
             encoder_outputs=None, past_key_values=None,
             use_cache=None, return_dict=True, training=False):
        """
        input_features: ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ íŠ¹ì§• [batch_size, n_mels, seq_len]
        decoder_input_ids: ë””ì½”ë” ì…ë ¥ í† í° ID [batch_size, seq_len]
        """
        use_cache = use_cache if use_cache is not None else self.config.use_cache
        
        # ì¸ì½”ë” ì²˜ë¦¬ (ì¸ì½”ë” ì¶œë ¥ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°)
        if encoder_outputs is None and input_features is not None:
            encoder_outputs = self.encoder(
                input_features,
                attention_mask=attention_mask,
                training=training
            )
        
        # ì¸ì½”ë” ì¶œë ¥
        encoder_hidden_states = encoder_outputs["last_hidden_state"]
        
        # ë””ì½”ë” ì…ë ¥ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ì‹œì‘ í† í° ìƒì„±
        if decoder_input_ids is None:
            batch_size = tf.shape(encoder_hidden_states)[0]
            decoder_input_ids = tf.fill((batch_size, 1), self.config.decoder_start_token_id)
        
        # ë””ì½”ë” í˜¸ì¶œ
        decoder_outputs = self.decoder(
            decoder_input_ids,
            encoder_hidden_states=encoder_hidden_states,
            attention_mask=decoder_attention_mask,
            encoder_attention_mask=attention_mask,
            past_key_values=past_key_values,
            use_cache=use_cache,
            training=training
        )
        
        if not return_dict:
            return (
                decoder_outputs["last_hidden_state"],
                decoder_outputs["past_key_values"],
                encoder_outputs["last_hidden_state"]
            )
        
        return {
            "last_hidden_state": decoder_outputs["last_hidden_state"],
            "past_key_values": decoder_outputs["past_key_values"],
            "encoder_last_hidden_state": encoder_outputs["last_hidden_state"],
            "encoder_hidden_states": encoder_outputs.get("hidden_states", None),
            "encoder_attentions": encoder_outputs.get("attentions", None),
            "decoder_hidden_states": decoder_outputs.get("hidden_states", None),
            "decoder_attentions": decoder_outputs.get("attentions", None),
            "cross_attentions": decoder_outputs.get("cross_attentions", None)
        }


# ì–¸ì–´ ëª¨ë¸ë§ì„ ìœ„í•œ Whisper ëª¨ë¸
class WhisperForConditionalGeneration(tf.keras.Model):
    def __init__(self, config):
        super(WhisperForConditionalGeneration, self).__init__()
        self.config = config
        
        # ê¸°ë³¸ Whisper ëª¨ë¸
        self.model = WhisperModel(config)
        
        # ì–¸ì–´ ëª¨ë¸ë§ í—¤ë“œ
        self.lm_head = tf.keras.layers.Dense(config.vocab_size, use_bias=False)
    
    def call(self, input_features, decoder_input_ids=None,
             attention_mask=None, decoder_attention_mask=None,
             encoder_outputs=None, past_key_values=None,
             labels=None, use_cache=None, return_dict=True, training=False):
        """
        input_features: ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ íŠ¹ì§• [batch_size, n_mels, seq_len]
        decoder_input_ids: ë””ì½”ë” ì…ë ¥ í† í° ID [batch_size, seq_len]
        labels: íƒ€ê²Ÿ í† í° ID [batch_size, seq_len]
        """
        # ë””ì½”ë” ì…ë ¥ì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ë ˆì´ë¸”ì—ì„œ ìƒì„±
        if decoder_input_ids is None and labels is not None:
            # ë ˆì´ë¸”ì˜ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì‹œí”„íŠ¸í•˜ì—¬ ë””ì½”ë” ì…ë ¥ ìƒì„± (teacher forcing)
            decoder_input_ids = tf.pad(
                labels[:, :-1], 
                [[0, 0], [1, 0]], 
                constant_values=self.config.decoder_start_token_id
            )
            tensor_monitor.track_tensor(decoder_input_ids, "shifted_decoder_input_ids")
        
        if labels is not None:
            tensor_monitor.track_tensor(labels, "training_labels")
        
        # Whisper ëª¨ë¸ í˜¸ì¶œ
        outputs = self.model(
            input_features=input_features,
            decoder_input_ids=decoder_input_ids,
            encoder_outputs=encoder_outputs,
            attention_mask=attention_mask,
            decoder_attention_mask=decoder_attention_mask,
            past_key_values=past_key_values,
            use_cache=use_cache,
            return_dict=True,
            training=training
        )
        
        # ì–¸ì–´ ëª¨ë¸ë§ í—¤ë“œ ì ìš©
        lm_logits = self.lm_head(outputs["last_hidden_state"])
        tensor_monitor.track_tensor(lm_logits, "lm_head_logits")
        
        # ì†ì‹¤ ê³„ì‚° (í•™ìŠµ ì¤‘ì´ê³  ë ˆì´ë¸”ì´ ì œê³µëœ ê²½ìš°)
        loss = None
        if training and labels is not None:
            # ì†ì‹¤ ê³„ì‚°ì„ ìœ„í•´ ë ˆì´ë¸” ì‹œí”„íŠ¸ (teacher forcing)
            shift_labels = labels[:, 1:]
            shift_logits = lm_logits[:, :-1, :]
            
            tensor_monitor.track_tensor(shift_labels, "shift_labels")
            tensor_monitor.track_tensor(shift_logits, "shift_logits")
            
            # ì†ì‹¤ ê³„ì‚° (êµì°¨ ì—”íŠ¸ë¡œí”¼)
            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(
                from_logits=True, reduction=tf.keras.losses.Reduction.NONE
            )
            
            loss = loss_fn(shift_labels, shift_logits)
            tensor_monitor.track_tensor(loss, "raw_loss")
            
            # íŒ¨ë”© í† í° ë§ˆìŠ¤í‚¹ (íŒ¨ë”© í† í°ì€ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸)
            if decoder_attention_mask is not None:
                loss = loss * tf.cast(decoder_attention_mask[:, :-1], dtype=loss.dtype)
                loss = tf.reduce_sum(loss) / tf.reduce_sum(tf.cast(decoder_attention_mask[:, :-1], dtype=loss.dtype))
            else:
                loss = tf.reduce_mean(loss)
            
            tensor_monitor.track_tensor(loss, "final_loss")
        
        if not return_dict:
            output = (lm_logits,) + outputs[1:]
            return ((loss,) + output) if loss is not None else output
        
        return {
            "loss": loss,
            "logits": lm_logits,
            "past_key_values": outputs["past_key_values"],
            "encoder_last_hidden_state": outputs["encoder_last_hidden_state"],
            "encoder_hidden_states": outputs.get("encoder_hidden_states", None),
            "encoder_attentions": outputs.get("encoder_attentions", None),
            "decoder_hidden_states": outputs.get("decoder_hidden_states", None),
            "decoder_attentions": outputs.get("decoder_attentions", None),
            "cross_attentions": outputs.get("cross_attentions", None)
        }
    
    def prepare_inputs_for_generation(self, decoder_input_ids, past_key_values=None, 
                                     attention_mask=None, use_cache=None, encoder_outputs=None,
                                     **kwargs):
        """
        ìƒì„±(ë””ì½”ë”©) ì¤‘ì— ì…ë ¥ì„ ì¤€ë¹„í•˜ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜
        """
        # ê³¼ê±° í‚¤/ê°’ì´ ì œê³µë˜ë©´ ë§ˆì§€ë§‰ í† í°ë§Œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
        if past_key_values is not None:
            decoder_input_ids = decoder_input_ids[:, -1:]
        
        return {
            "decoder_input_ids": decoder_input_ids,
            "past_key_values": past_key_values,
            "encoder_outputs": encoder_outputs,
            "attention_mask": attention_mask,
            "use_cache": use_cache
        }
    
    def generate(self, input_features, max_length=None, min_length=None, 
                 num_beams=None, temperature=1.0, top_k=None, top_p=None,
                 repetition_penalty=None, attention_mask=None, **kwargs):
        """
        í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
        """
        max_length = max_length if max_length is not None else self.config.max_target_positions
        min_length = min_length if min_length is not None else 0
        num_beams = num_beams if num_beams is not None else 1
        temperature = temperature if temperature is not None else 1.0
        top_k = top_k if top_k is not None else 50
        top_p = top_p if top_p is not None else 1.0
        repetition_penalty = repetition_penalty if repetition_penalty is not None else 1.0
        
        batch_size = tf.shape(input_features)[0]
        
        # ì¸ì½”ë” ì¶œë ¥ ê³„ì‚°
        encoder_outputs = self.model.encoder(
            input_features=input_features,
            attention_mask=attention_mask,
            training=False
        )
        
        # ë””ì½”ë” ì‹œì‘ í† í° ì„¤ì •
        decoder_input_ids = tf.fill((batch_size, 1), self.config.decoder_start_token_id)
        
        # ìƒì„± ë£¨í”„ (ê°„ë‹¨í•œ ê·¸ë¦¬ë”” ë””ì½”ë”© êµ¬í˜„)
        for _ in range(max_length):
            # ëª¨ë¸ í˜¸ì¶œ
            outputs = self.model(
                input_features=None,  # ì¸ì½”ë”ëŠ” ì´ë¯¸ ì‹¤í–‰ë¨
                decoder_input_ids=decoder_input_ids,
                encoder_outputs=encoder_outputs,
                attention_mask=attention_mask,
                use_cache=True,
                training=False
            )
            
            # ë‹¤ìŒ í† í° ì˜ˆì¸¡
            next_token_logits = outputs["logits"][:, -1, :]
            
            # ì˜¨ë„ ì ìš©
            if temperature != 1.0:
                next_token_logits = next_token_logits / temperature
            
            # Top-k ìƒ˜í”Œë§
            if top_k > 0:
                indices_to_remove = tf.argsort(next_token_logits, direction='DESCENDING')[:, top_k:]
                indices_to_remove = tf.expand_dims(indices_to_remove, -1)
                next_token_logits = tf.tensor_scatter_nd_update(
                    next_token_logits,
                    indices_to_remove,
                    tf.fill([tf.shape(indices_to_remove)[0], tf.shape(indices_to_remove)[1]], -float('inf'))
                )
            
            # ë‹¤ìŒ í† í° ì„ íƒ
            if num_beams > 1:
                # ë¹” ì„œì¹˜ êµ¬í˜„ì€ ë³µì¡í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ìƒëµ
                pass
            else:
                # ê·¸ë¦¬ë”” ë””ì½”ë”©
                next_tokens = tf.argmax(next_token_logits, axis=-1, output_type=tf.int32)
            
            # EOS í† í° ì²´í¬
            eos_tokens = tf.equal(next_tokens, self.config.eos_token_id)
            
            # ìƒˆ í† í° ì¶”ê°€
            decoder_input_ids = tf.concat([decoder_input_ids, tf.expand_dims(next_tokens, -1)], axis=-1)
            
            # ëª¨ë“  ì‹œí€€ìŠ¤ê°€ EOS í† í°ì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸
            if tf.reduce_all(eos_tokens):
                break
        
        return decoder_input_ids
    
    def train_step(self, data):
        """
        í•™ìŠµ ìŠ¤í… êµ¬í˜„
        """
        features, labels = data
        
        with tf.GradientTape() as tape:
            # ëª¨ë¸ ìˆœì „íŒŒ
            outputs = self(features, labels=labels, training=True)
            loss = outputs["loss"]
        
        # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë° ì ìš©
        gradients = tape.gradient(loss, self.trainable_variables)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        self.compiled_metrics.update_state(labels, outputs["logits"])
        
        # ê²°ê³¼ ë°˜í™˜
        results = {m.name: m.result() for m in self.metrics}
        results.update({"loss": loss})
        
        return results


# ============ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë° í•™ìŠµ ê´€ë ¨ ì½”ë“œ ============ #

# ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜
def extract_fbank_features(waveform, sample_rate=16000, n_mels=80, n_fft=400, hop_length=160):
    """
    ì˜¤ë””ì˜¤ íŒŒí˜•ì—ì„œ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ íŠ¹ì§• ì¶”ì¶œ
    """
    # TensorFlowë¡œ FFT ê³„ì‚°
    stfts = tf.signal.stft(
        waveform, 
        frame_length=n_fft, 
        frame_step=hop_length, 
        fft_length=n_fft
    )
    
    # ìŠ¤í™íŠ¸ëŸ¼ì˜ íŒŒì›Œ ê³„ì‚°
    power_spectrograms = tf.math.square(tf.abs(stfts))
    
    # ë©œ í•„í„°ë±…í¬ ìƒì„±
    num_spectrogram_bins = n_fft // 2 + 1
    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(
        n_mels, num_spectrogram_bins, sample_rate, 0, sample_rate // 2
    )
    
    # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê³„ì‚°
    mel_spectrograms = tf.tensordot(power_spectrograms, linear_to_mel_weight_matrix, 1)
    
    # ë¡œê·¸ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê³„ì‚°
    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)
    
    return log_mel_spectrograms


# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_text(text, tokenizer):
    """
    í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    """
    # í…ìŠ¤íŠ¸ ì •ê·œí™” ë° í† í°í™”
    tokens = tokenizer.encode(text)
    
    # ì‹œì‘ ë° ì¢…ë£Œ í† í° ì¶”ê°€
    tokens = [tokenizer.bos_token_id] + tokens + [tokenizer.eos_token_id]
    
    return tokens


# ë”ë¯¸ ë°ì´í„°ì…‹ ìƒì„±
def create_dummy_dataset(batch_size, n_mels=80, seq_len=3000, max_target_length=100):
    """
    í•™ìŠµìš© ë”ë¯¸ ì˜¤ë””ì˜¤-í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # ì¶©ë¶„íˆ í° ë”ë¯¸ ë°ì´í„°ì…‹
    num_samples = 50  # ë°ì´í„°ì…‹ í¬ê¸°
    
    # ë”ë¯¸ íŠ¹ì„± (ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨) ìƒì„±
    dummy_features = np.random.randn(num_samples, n_mels, seq_len).astype(np.float32)
    
    # ë”ë¯¸ ë ˆì´ë¸” (í† í° ID) ìƒì„± - ì²« ë²ˆì§¸ í† í°ì€ BOS(1), ë§ˆì§€ë§‰ í† í°ì€ EOS(2)ë¡œ ì„¤ì •
    dummy_labels = np.zeros((num_samples, max_target_length), dtype=np.int32)
    
    # ê° ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ (50~90 ì‚¬ì´ì˜ ë¬´ì‘ìœ„ ê¸¸ì´)
    sequence_lengths = np.random.randint(50, 90, size=num_samples)
    
    for i in range(num_samples):
        # ì²« ë²ˆì§¸ í† í°ì€ BOS í† í°
        dummy_labels[i, 0] = 1  # BOS token
        
        # ì¤‘ê°„ í† í°ì€ ëœë¤ (3ë¶€í„° 100 ì‚¬ì´ì˜ ê°’)
        length = sequence_lengths[i]
        dummy_labels[i, 1:length-1] = np.random.randint(3, 100, size=length-2)
        
        # ë§ˆì§€ë§‰ í† í°ì€ EOS í† í°
        dummy_labels[i, length-1] = 2  # EOS token
    
    # TensorFlow ë°ì´í„°ì…‹ ìƒì„±
    dataset = tf.data.Dataset.from_tensor_slices((dummy_features, dummy_labels))
    
    # ë°°ì¹˜ ì„¤ì • ë° ë°˜ë³µ
    return dataset.batch(batch_size).repeat()


@tf.function
def distributed_train_step(strategy, model, dist_inputs, optimizer):
    """ë¶„ì‚° í•™ìŠµì„ ìœ„í•œ ìŠ¤í… í•¨ìˆ˜ (í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì • í¬í•¨)"""
    
    def train_step(inputs):
        features, labels = inputs
        
        # ìŠ¤í… ì‹œì‘ ì‹œ í…ì„œ ëª¨ë‹ˆí„° ë¦¬ì…‹
        tensor_monitor.reset_step()
        
        with tf.GradientTape() as tape:
            # ëª¨ë¸ í˜¸ì¶œ
            try:
                outputs = model(features, labels=labels, training=True)
                loss = outputs["loss"]
                
                # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë° ì ìš©
                gradients = tape.gradient(loss, model.trainable_variables)
                
                # ê·¸ë˜ë””ì–¸íŠ¸ í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì •
                for i, grad in enumerate(gradients):
                    if grad is not None:
                        tensor_monitor.track_tensor(grad, f"gradient_{i}")
                
                optimizer.apply_gradients(zip(gradients, model.trainable_variables))
                
                return loss
            except Exception as e:
                print(f"í•™ìŠµ ìŠ¤í… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                # í˜•íƒœ ë””ë²„ê¹… ì¶œë ¥
                print(f"features.shape: {features.shape}")
                print(f"labels.shape: {labels.shape}")
                raise
    
    # ë¶„ì‚° ì „ëµìœ¼ë¡œ í•™ìŠµ ìŠ¤í… ì‹¤í–‰
    per_replica_losses = strategy.run(train_step, args=(dist_inputs,))
    
    # ì†ì‹¤ ê°’ ì§‘ê³„
    return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)


def setup_model_profiling(model, profiler):
    """ëª¨ë¸ì˜ ëª¨ë“  ë ˆì´ì–´ì— í”„ë¡œíŒŒì¼ëŸ¬ë¥¼ ì„¤ì •"""
    def set_profiler_recursive(layer):
        if hasattr(layer, 'set_profiler'):
            layer.set_profiler(profiler)
        
        # í•˜ìœ„ ë ˆì´ì–´ë“¤ì—ë„ ì¬ê·€ì ìœ¼ë¡œ ì ìš©
        if hasattr(layer, 'layers'):
            for sublayer in layer.layers:
                set_profiler_recursive(sublayer)
        
        # ì•ˆì „í•œ ì†ì„± í™•ì¸ - ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” ì†ì„±ë“¤ì€ ì œì™¸
        excluded_attrs = {
            'input', 'output', 'input_shape', 'output_shape', 
            'input_spec', 'output_spec', '_input_layers', '_output_layers',
            '_inbound_nodes', '_outbound_nodes', 'built', '_built_input_shape'
        }
        
        # ëª¨ë“  ì†ì„±ì„ í™•ì¸í•˜ì—¬ ë ˆì´ì–´ì¸ ê²ƒë“¤ì— ì ìš©
        for attr_name in dir(layer):
            if (not attr_name.startswith('_') and 
                attr_name not in excluded_attrs):
                try:
                    attr = getattr(layer, attr_name)
                    if (isinstance(attr, tf.keras.layers.Layer) and 
                        hasattr(attr, 'set_profiler')):
                        attr.set_profiler(profiler)
                except (AttributeError, ValueError, RuntimeError):
                    # ë ˆì´ì–´ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë‹¤ë¥¸ ì´ìœ ë¡œ ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ
                    continue
    
    set_profiler_recursive(model)
    print(f"ğŸ”§ ëª¨ë“  ë ˆì´ì–´ì— í”„ë¡œíŒŒì¼ëŸ¬ ì„¤ì • ì™„ë£Œ")


# Whisper í•™ìŠµ í•¨ìˆ˜ (í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì • í¬í•¨)
def train_whisper_with_profiling(strategy, model_type="small", num_epochs=1, learning_rate=1e-4):
    """Whisper ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ (ê³ ê¸‰ í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì • í¬í•¨)"""
    
    # í…ì„œ í”„ë¡œíŒŒì¼ëŸ¬ ì´ˆê¸°í™”
    profiler = TensorProfiler(log_dir='/workspace/tensor_logs')
    
    try:
        with strategy.scope():
            # ëª¨ë¸ ìƒì„±
            model = create_whisper_model(model_type=model_type)
            
            # ëª¨ë¸ì„ ë¹Œë“œí•˜ê¸° ìœ„í•´ ë”ë¯¸ ë°ì´í„°ë¡œ í•œ ë²ˆ í˜¸ì¶œ
            dummy_features = tf.random.normal((1, 80, 3000))  # [batch, n_mels, seq_len]
            dummy_labels = tf.random.uniform((1, 100), minval=0, maxval=1000, dtype=tf.int32)
            
            try:
                # ëª¨ë¸ ë¹Œë“œ
                _ = model(dummy_features, labels=dummy_labels, training=False)
                print("ğŸ”§ ëª¨ë¸ ë¹Œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"ëª¨ë¸ ë¹Œë“œ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
            
            # ëª¨ë¸ì— í”„ë¡œíŒŒì¼ëŸ¬ ì„¤ì •
            setup_model_profiling(model, profiler)
            
            # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
            
            # ë©”íŠ¸ë¦­ ì„¤ì •
            metrics = [
                tf.keras.metrics.SparseCategoricalAccuracy(name="accuracy"),
                tf.keras.metrics.Mean(name="loss")
            ]
            
            # ëª¨ë¸ ì»´íŒŒì¼
            model.compile(optimizer=optimizer, metrics=metrics)
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = create_dummy_dataset(GLOBAL_BATCH_SIZE)
        dist_dataset = strategy.experimental_distribute_dataset(train_dataset)
        
        # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
        checkpoint_dir = '/workspace/checkpoints'
        os.makedirs(checkpoint_dir, exist_ok=True)
        checkpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)
        
        # í•™ìŠµ ë£¨í”„
        step = 0
        iterator = iter(dist_dataset)
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()
        
        print(f"=== Tiresias ìŠ¤íƒ€ì¼ í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì •ì„ í¬í•¨í•œ Whisper-{model_type} í•™ìŠµ ì‹œì‘ ===")
        
        # ì²« ë²ˆì§¸ ìŠ¤í…ì—ì„œ ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œê¹…
        profiler.start_step(step)
        profiler.log_model_parameters(model)
        profiler.end_step()
        step += 1
        
        for epoch in range(num_epochs):
            print(f"Epoch {epoch+1}/{num_epochs}")
            
            for batch_idx in range(MAX_ITERATIONS):
                # ë¶„ì‚° ë°ì´í„°ì…‹ì—ì„œ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸°
                try:
                    inputs = next(iterator)
                except StopIteration:
                    iterator = iter(dist_dataset)
                    inputs = next(iterator)
                
                # í˜„ì¬ ì‹œê°„ ê¸°ë¡
                step_start = time.time()
                
                # í”„ë¡œíŒŒì¼ë§ ìŠ¤í… ì‹œì‘
                profiler.start_step(step)
                
                # ë¶„ì‚° í•™ìŠµ ìŠ¤í… ì‹¤í–‰ (í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì • í¬í•¨)
                loss = distributed_train_step(strategy, model, inputs, optimizer)
                
                # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…
                memory_info = profiler.log_memory_usage()
                
                # í”„ë¡œíŒŒì¼ë§ ìŠ¤í… ì¢…ë£Œ
                step_tensor_size = profiler.end_step()
                
                # ìŠ¤í… ì™„ë£Œ ì‹œê°„
                step_end = time.time()
                step_duration = step_end - step_start
                elapsed = step_end - start_time
                
                # ë§¤ 10ìŠ¤í…ë§ˆë‹¤ ìƒì„¸ ë¡œê¹…
                if step % 10 == 0:
                    print(f"ğŸ“Š Step {step} - Loss: {loss.numpy():.4f}")
                    print(f"   ğŸ’¾ GPU Memory: {memory_info['gpu_memory_mb']:.1f} MB, CPU Memory: {memory_info['cpu_memory_mb']:.1f} MB")
                    print(f"   ğŸ“ TensorSize: {step_tensor_size:.2f} MB")
                    print(f"   â±ï¸  Time: {time.strftime('%H:%M:%S')} (ê²½ê³¼: {elapsed:.1f}ì´ˆ, ìŠ¤í…: {step_duration:.2f}ì´ˆ)")
                else:
                    print(f"Step {step}, Loss: {loss.numpy():.4f}, TensorSize: {step_tensor_size:.2f} MB")
                
                step += 1
            
            # ì—í¬í¬ ì¢…ë£Œ í›„ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint.save(os.path.join(checkpoint_dir, f"whisper_{model_type}_epoch_{epoch+1}"))
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ” **Tiresias TensorSize ì¸¡ì • ì™„ë£Œ**")
        print("="*60)
        
        summary = profiler.save_final_results()
        tiresias_tensorsize = summary['tiresias_tensorsize_mb']
        model_skewness = summary['model_skewness']
        
        print(f"ğŸ” **Tiresias TensorSize ê²°ê³¼**")
        print(f"whisper_{model_type}    {tiresias_tensorsize:.1f} MB")
        print()
        
        print(f"ğŸ“Š **ëª¨ë¸ Skewness ê²°ê³¼**")
        print(f"whisper_{model_type}    {model_skewness:.1f}")
        print()
        
        # ê¸°ì¡´ ëª¨ë¸ë“¤ê³¼ ë¹„êµí‘œ ì¶œë ¥
        reference_models = {
            'alexnet': 6.7,
            'vgg16': 527.8,
            'googlenet': 26.7,
            'inception3': 90.9,
            'resnet50': 97.5,
            'resnet110': 6.6,
            'resnet44': 2.5,
            'resnet56': 3.3,
            'densenet100_k12': 8.5,
            'densenet40_k12': 1.3,
            'bert': 1560,
            'gpt2': 4000
        }
        
        # ë ˆê±°ì‹œ skewness ë°ì´í„°
        reference_skewness = {
            'alexnet': 2.6,
            'vgg16': 5.1,
            'googlenet': 4.2,
            'inception3': 4.2,
            'resnet50': 3.8,
            'resnet110': 2.3,
            'resnet44': 2.4,
            'resnet56': 2.3,
            'densenet100_k12': 1.9,
            'densenet40_k12': 1.9,
            'bert': 7.3,
            'bertl': 7.2,
            'gpt2': 8,
            'gpt2m': 9.9,
            'gpt2l': 9.8,
            'gpt2xl': 8
        }
        
        print("ğŸ“Š **ëª¨ë¸ë³„ TensorSize ë¹„êµ** (ë‹¨ìœ„: MB)")
        print("model\t\ttensorsizes")
        for model_name, tensorsize in reference_models.items():
            print(f"{model_name}\t\t{tensorsize}")
        print(f"whisper_{model_type}\t{tiresias_tensorsize:.1f} â¬…ï¸ **ì´ë²ˆ ì¸¡ì •ê°’**")
        print()
        
        print("ğŸ“Š **ëª¨ë¸ë³„ Skewness ë¹„êµ**")
        print("model\t\tskewness")
        for model_name, skewness in reference_skewness.items():
            print(f"{model_name}\t\t{skewness}")
        print(f"whisper_{model_type}\t{model_skewness:.1f} â¬…ï¸ **ì´ë²ˆ ì¸¡ì •ê°’**")
        print()
        
        # ì¹´í…Œê³ ë¦¬ ë¶„ì„
        if tiresias_tensorsize < 10:
            category = "ê²½ëŸ‰ ëª¨ë¸"
        elif tiresias_tensorsize < 100:
            category = "ì¤‘ê°„ í¬ê¸° ëª¨ë¸"
        elif tiresias_tensorsize < 1000:
            category = "ëŒ€í˜• ëª¨ë¸"
        else:
            category = "ì´ˆëŒ€í˜• ëª¨ë¸"
        
        # Skewness ë¶„ì„
        if model_skewness < 2.0:
            skew_category = "ë‚®ì€ ì™œê³¡ë„ (ê· ë“±í•œ í…ì„œ ë¶„í¬)"
        elif model_skewness < 5.0:
            skew_category = "ì¤‘ê°„ ì™œê³¡ë„"
        elif model_skewness < 8.0:
            skew_category = "ë†’ì€ ì™œê³¡ë„"
        else:
            skew_category = "ë§¤ìš° ë†’ì€ ì™œê³¡ë„ (ë¶ˆê· ë“±í•œ í…ì„œ ë¶„í¬)"
        
        print("ğŸ“ˆ **ë¶„ì„ ê²°ê³¼:**")
        print(f"- TensorSize ì¹´í…Œê³ ë¦¬: {category}")
        print(f"- Skewness ì¹´í…Œê³ ë¦¬: {skew_category}")
        
        # ë¹„ìŠ·í•œ í¬ê¸°ì˜ ëª¨ë¸ ì°¾ê¸°
        closest_models = []
        for model_name, size in reference_models.items():
            if abs(size - tiresias_tensorsize) < tiresias_tensorsize * 0.3:  # 30% ì´ë‚´
                closest_models.append((model_name, size))
        
        if closest_models:
            closest_names = [name for name, _ in closest_models]
            print(f"- TensorSize ë¹„êµ: {' ~ '.join(closest_names)} ìˆ˜ì¤€")
        
        # ë¹„ìŠ·í•œ skewnessì˜ ëª¨ë¸ ì°¾ê¸°
        closest_skew_models = []
        for model_name, skew in reference_skewness.items():
            if abs(skew - model_skewness) < 1.0:  # 1.0 ì´ë‚´
                closest_skew_models.append((model_name, skew))
        
        if closest_skew_models:
            closest_skew_names = [name for name, _ in closest_skew_models]
            print(f"- Skewness ë¹„êµ: {' ~ '.join(closest_skew_names)} ìˆ˜ì¤€")
        
        print(f"- í•œ iterationë‹¹ ì²˜ë¦¬í•˜ëŠ” í…ì„œ ì´ í¬ê¸°: {tiresias_tensorsize:.1f} MB")
        print(f"- í…ì„œ í¬ê¸° ë¶„í¬ì˜ ì™œê³¡ë„: {model_skewness:.1f}")
        print()
        
        print("ğŸ’¡ **ì§€í‘œ ì˜ë¯¸:**")
        print("- TensorSize: í•œ ë²ˆì˜ í•™ìŠµ iterationì—ì„œ ì²˜ë¦¬ë˜ëŠ” ëª¨ë“  í…ì„œì˜ ì´ ë©”ëª¨ë¦¬ í¬ê¸°(MB)")
        print("- Skewness: í…ì„œ í¬ê¸° ë¶„í¬ì˜ ë¹„ëŒ€ì¹­ì„± (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê· ë“±í•œ ë¶„í¬)")
        print("  * ì–‘ìˆ˜: í° í…ì„œê°€ ì ê³  ì‘ì€ í…ì„œê°€ ë§ìŒ")
        print("  * ìŒìˆ˜: ì‘ì€ í…ì„œê°€ ì ê³  í° í…ì„œê°€ ë§ìŒ")
        print("  * ì ˆëŒ“ê°’ì´ í´ìˆ˜ë¡: ë” ë¶ˆê· ë“±í•œ ë¶„í¬")
        print("- GPU ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ì˜ˆì¸¡ê³¼ ì‘ì—… ìŠ¤ì¼€ì¤„ë§ ìµœì í™”ì— ì‚¬ìš©")
        print("="*60)
        
        return model, summary
        
    finally:
        # í”„ë¡œíŒŒì¼ëŸ¬ ì¢…ë£Œ
        profiler.close()


# í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê¹… í•¨ìˆ˜
def log_tensor_sizes(step, save_dir):
    """í…ì„œ ì‚¬ì´ì¦ˆë¥¼ ë¡œê¹…í•˜ê³  íŒŒì¼ì— ì €ì¥"""
    summary = tensor_monitor.get_step_summary()
    step_size_mb = summary['step_total_size'] / (1024 * 1024)  # MB ë‹¨ìœ„ë¡œ ë³€í™˜
    
    print(f"Step {step} - Total tensor size: {step_size_mb:.2f} MB")
    
    # ìƒìœ„ 10ê°œ operationë³„ í…ì„œ ì‚¬ì´ì¦ˆ ì¶œë ¥
    op_sizes = summary['operation_sizes']
    sorted_ops = sorted(op_sizes.items(), key=lambda x: x[1], reverse=True)[:10]
    
    print("Top 10 operations by tensor size:")
    for op_name, size in sorted_ops:
        size_mb = size / (1024 * 1024)
        print(f"  {op_name}: {size_mb:.2f} MB")
    
    # íŒŒì¼ì— ì €ì¥
    os.makedirs(save_dir, exist_ok=True)
    
    # ìŠ¤í…ë³„ ì´ í…ì„œ ì‚¬ì´ì¦ˆ ì €ì¥
    with open(os.path.join(save_dir, 'step_tensor_sizes.txt'), 'a') as f:
        f.write(f"{step},{step_size_mb:.2f}\n")
    
    # Operationë³„ í…ì„œ ì‚¬ì´ì¦ˆ ì €ì¥ (JSON í˜•íƒœ)
    tensor_log = {
        'step': step,
        'total_size_mb': step_size_mb,
        'operation_sizes': {op: size/(1024*1024) for op, size in op_sizes.items()}
    }
    
    with open(os.path.join(save_dir, f'tensor_sizes_step_{step}.json'), 'w') as f:
        json.dump(tensor_log, f, indent=2)


# Whisper ëª¨ë¸ ìƒì„± í•¨ìˆ˜
def create_whisper_model(model_type="small"):
    """
    ì§€ì •ëœ í¬ê¸°ì˜ Whisper ëª¨ë¸ ìƒì„±
    """
    config = WhisperConfig()
    
    # ëª¨ë¸ í¬ê¸°ì— ë”°ë¥¸ ì„¤ì • ì¡°ì •
    if model_type == "tiny":
        config.d_model = 384
        config.encoder_layers = 4
        config.encoder_attention_heads = 6
        config.decoder_layers = 4
        config.decoder_attention_heads = 6
        config.d_ff = 1536
    elif model_type == "base":
        config.d_model = 512
        config.encoder_layers = 6
        config.encoder_attention_heads = 8
        config.decoder_layers = 6
        config.decoder_attention_heads = 8
        config.d_ff = 2048
    elif model_type == "medium":
        config.d_model = 1024
        config.encoder_layers = 24
        config.encoder_attention_heads = 16
        config.decoder_layers = 24
        config.decoder_attention_heads = 16
        config.d_ff = 4096
    elif model_type == "large":
        config.d_model = 1280
        config.encoder_layers = 32
        config.encoder_attention_heads = 20
        config.decoder_layers = 32
        config.decoder_attention_heads = 20
        config.d_ff = 5120
    
    # Whisper-smallì€ ê¸°ë³¸ê°’ ì‚¬ìš© (config ìƒì„± ì‹œ ì´ë¯¸ ì„¤ì •ë¨)
    
    return WhisperForConditionalGeneration(config)


# ì¶”ë¡  í•¨ìˆ˜
def transcribe_audio(model, audio_path, tokenizer=None, max_length=448):
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    """
    # ì˜¤ë””ì˜¤ ë¡œë“œ ë° ì „ì²˜ë¦¬
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—¬ê¸°ì— ì˜¤ë””ì˜¤ ë¡œë“œ ì½”ë“œê°€ í•„ìš”í•¨
    # ì—¬ê¸°ì„œëŠ” ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
    dummy_waveform = np.random.randn(16000 * 30).astype(np.float32)  # 30ì´ˆ ì˜¤ë””ì˜¤
    
    # íŠ¹ì§• ì¶”ì¶œ
    features = extract_fbank_features(dummy_waveform)
    features = tf.expand_dims(features, 0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    
    # ì¶”ë¡ 
    decoder_input_ids = tf.fill((1, 1), model.config.decoder_start_token_id)
    outputs = model.generate(features, max_length=max_length)
    
    # í† í° IDì—ì„œ í…ìŠ¤íŠ¸ ë³€í™˜
    if tokenizer is not None:
        transcription = tokenizer.decode(outputs[0].numpy())
    else:
        # í† í¬ë‚˜ì´ì €ê°€ ì—†ëŠ” ê²½ìš° IDë§Œ ë°˜í™˜
        transcription = outputs[0].numpy()
    
    return transcription


# ë©”ì¸ í•¨ìˆ˜
def main(strategy):
    print("Whisper-small ë¶„ì‚° í•™ìŠµ ì‹œì‘ (Tiresias ìŠ¤íƒ€ì¼ í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì • í¬í•¨)...")
    
    # ë„¤íŠ¸ì›Œí¬ ë° GPU ëª¨ë‹ˆí„°ë§ ì‹œì‘
    os.system('sh /workspace/network.sh &')  # network profile
    os.system('sh /workspace/gpu.sh &')  # gpu profile
    print('''
========================
network profile started!
Tiresias-style tensor size monitoring enabled!
========================''')
    
    # JCT ì¸¡ì • ì‹œì‘
    start_time = time.time()
    
    # ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ (Tiresias ìŠ¤íƒ€ì¼ í…ì„œ ì‚¬ì´ì¦ˆ ì¸¡ì • í¬í•¨)
    model, tensor_summary = train_whisper_with_profiling(strategy, model_type="small")
    
    # JCT ì¸¡ì • ì¢…ë£Œ
    end_time = time.time()
    jct = end_time - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print("Training completed.")
    print("jct:", jct)
    
    # JCT íŒŒì¼ ì €ì¥
    try:
        model_txt = open('/workspace/model.txt', 'r')
        save_dir_name = model_txt.read()
        result_dir = '/result/' + save_dir_name.strip()
        os.makedirs(result_dir, exist_ok=True)
        
        jct_file = open(result_dir + '/' + task_type + '_' + str(task_index) + '_jct.txt', 'w')
        jct_file.write('%.2f' % (float(jct)))
        jct_file.close()
        model_txt.close()
        
        # í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê·¸ë¥¼ ê²°ê³¼ ë””ë ‰í† ë¦¬ì— ë³µì‚¬
        tensor_log_source = '/workspace/tensor_logs'
        tensor_log_dest = result_dir + '/tensor_logs'
        
        try:
            import shutil
            if os.path.exists(tensor_log_source):
                shutil.copytree(tensor_log_source, tensor_log_dest, dirs_exist_ok=True)
                print(f"ğŸ” í…ì„œ ì‚¬ì´ì¦ˆ ë¡œê·¸ê°€ {tensor_log_dest}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"í…ì„œ ë¡œê·¸ ë³µì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        # Tiresias ê²°ê³¼ë¥¼ ë³„ë„ íŒŒì¼ì— ì €ì¥
        tiresias_result_file = result_dir + '/tiresias_tensorsize_result.txt'
        with open(tiresias_result_file, 'w') as f:
            f.write(f"model,tensorsize_mb\n")
            f.write(f"whisper_small,{tensor_summary['tiresias_tensorsize_mb']:.1f}\n")
        print(f"ğŸ” Tiresias ê²°ê³¼ê°€ {tiresias_result_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # Skewness ê²°ê³¼ë¥¼ ë³„ë„ íŒŒì¼ì— ì €ì¥ (ë ˆê±°ì‹œ í¬ë§·)
        skewness_result_file = result_dir + '/legacy_skewness_result.txt'
        with open(skewness_result_file, 'w') as f:
            f.write(f"model,skewness\n")
            f.write(f"whisper_small,{tensor_summary['model_skewness']:.1f}\n")
        print(f"ğŸ“Š Skewness ê²°ê³¼ê°€ {skewness_result_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # í†µí•© ê²°ê³¼ íŒŒì¼ ì €ì¥
        combined_result_file = result_dir + '/combined_metrics_result.txt'
        with open(combined_result_file, 'w') as f:
            f.write(f"model,tensorsize_mb,skewness\n")
            f.write(f"whisper_small,{tensor_summary['tiresias_tensorsize_mb']:.1f},{tensor_summary['model_skewness']:.1f}\n")
        print(f"ğŸ”— í†µí•© ê²°ê³¼ê°€ {combined_result_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ëª¨ë¸ ì €ì¥
    model_path = os.path.join(CACHE_DIR, "whisper_small_model")
    try:
        model.save_weights(model_path)
        print(f"ëª¨ë¸ì´ {model_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print("\nğŸ‰ **Whisper í…ì„œ ë¶„ì„ ì™„ë£Œ!**")
    print(f"ğŸ“Š ìµœì¢… TensorSize: {tensor_summary['tiresias_tensorsize_mb']:.1f} MB")
    print(f"ğŸ“Š ìµœì¢… Skewness: {tensor_summary['model_skewness']:.1f}")
    print("ğŸ” ìƒì„¸ ë¡œê·¸ëŠ” /workspace/tensor_logs ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='Whisper-small Distributed Speech Recognition with Tensor Size Monitoring')
    parser.add_argument('--num_batches', type=int, default=40, help='num_batches per replica, default is set 40')
    parser.add_argument('--batch_size', type=int, default=1, help='batch size per replica, default is set 1')
    parser.add_argument('--log_tensor_freq', type=int, default=1, help='frequency of tensor size logging (every N steps), default is 1')
    args = parser.parse_args()

    # í™˜ê²½ ì„¤ì •
    tf_config = json.loads(os.environ.get('TF_CONFIG') or '{}')
    task_config = tf_config.get('task', {})
    task_type = task_config.get('type')
    task_index = task_config.get('index')

    # ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë¡œì»¬ ë””ë ‰í† ë¦¬ ì„¤ì •
    CACHE_DIR = '/workspace/model_cache'  # ì»¨í…Œì´ë„ˆ ë‚´ ì‚¬ì „ ì¤€ë¹„ëœ ëª¨ë¸ ìºì‹œ ê²½ë¡œ
    DATASET_DIR = '/workspace/datasets'  # ì»¨í…Œì´ë„ˆ ë‚´ ì‚¬ì „ ì¤€ë¹„ëœ ë°ì´í„°ì…‹ ê²½ë¡œ

    # ë¶„ì‚° í•™ìŠµ ì „ëµ ì„¤ì •
    strategy = tf.distribute.MultiWorkerMirroredStrategy()

    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    BATCH_SIZE_PER_REPLICA = args.batch_size
    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
    MAX_ITERATIONS = args.num_batches
    BUFFER_SIZE = 10000
    TENSOR_LOG_FREQ = args.log_tensor_freq

    print(f'batch size per replica: {BATCH_SIZE_PER_REPLICA}, global batch size: {GLOBAL_BATCH_SIZE}')
    print(f'num_batches: {MAX_ITERATIONS}')
    print(f'tensor logging frequency: every {TENSOR_LOG_FREQ} steps')
    
    main(strategy)